import FinanceDataReader as fdr
import sqlite3
import pandas as pd
import numpy as np
import joblib
from lightgbm import LGBMClassifier, early_stopping, log_evaluation
from sklearn.metrics import precision_score
import matplotlib.pyplot as plt

# 1. í•˜ì´ë¸Œë¦¬ë“œ ì¢…ëª© í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
def get_hybrid_top_codes():
    print("[1/5] ìš°ëŸ‰ ëŒ€ì¥ì£¼ í•„í„°ë§ ì¤‘ (LGBM ë²„ì „)...")
    df_krx = fdr.StockListing('KOSPI')
    top_200 = df_krx.sort_values(by='Marcap', ascending=False).head(200)
    hybrid_top = top_200.sort_values(by='Volume', ascending=False).head(100)
    return hybrid_top['Code'].tolist()

# 2. ë°ì´í„° ê°€ê³µ ë° ì§€í‘œ ìƒì„± (XGBoostì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ í•¨)
def load_and_preprocess(codes):
    print(f"[2/5] {len(codes)}ê°œ ì¢…ëª© ë°ì´í„° ê°€ê³µ ë° ìµœì‹  ì§€í‘œ(VWAP, OBV ë“±) ì ìš© ì¤‘...")
    conn = sqlite3.connect('kospi_stock_data.db')
    all_data = []
    
    for code in codes:
        df = pd.read_sql(f"SELECT * FROM daily_stock_quotes WHERE Code = '{code}' ORDER BY Date ASC", conn)
        if len(df) < 150: continue
        
        # 1. ê¸°ì¡´ íŒŒìƒ ì§€í‘œ ìœ ì§€
        df['Vol_Change'] = df['Volume'].pct_change()
        df['MA_Ratio'] = df['Close'] / (df['MA20'] + 1e-9)
        df['BB_Pos'] = (df['Close'] - df['BBL']) / (df['BBU'] - df['BBL'] + 1e-9)
        df['RSI_Slope'] = df['RSI'].diff() 
        df['Range_Ratio'] = (df['High'] - df['Low']) / (df['Close'] + 1e-9)
        df['Vol_Momentum'] = df['Volume'] / (df['Volume'].rolling(window=5).mean() + 1e-9)
        df['Dist_MA5'] = df['Close'] / (df['MA5'] + 1e-9)

        # ìµì¼ ë°ì´í„° ìƒì„±
        df['Next_Open'] = df['Open'].shift(-1)
        df['Next_High'] = df['High'].shift(-1)
        df['Next_Low'] = df['Low'].shift(-1)
        df['Next_Close'] = df['Close'].shift(-1)

        # ==========================================
        # ğŸš€ [v12.1 ì™„í™”ëœ ì •ë‹µì§€] í˜„ì‹¤ì ì¸ KOSPI íƒ€ê²ŸíŒ…
        # ==========================================
        
        # 1. ê³ ê°€ê°€ +2.0% ë„ë‹¬ (ê¸°ì¡´ 2.5%ì—ì„œ ì™„í™”)
        hit_target = (df['Next_High'] / (df['Next_Open'] + 1e-9)) >= 1.020   
        
        # 2. ì €ê°€ê°€ -2.5% ë¯¸ë§Œìœ¼ë¡œ ì•ˆ ë¹ ì§ (ê¸°ì¡´ -1.5%ì—ì„œ ëŒ€í­ ì™„í™”í•˜ì—¬ í”ë“¤ë¦¼ í—ˆìš©)
        no_stop_loss = (df['Next_Low'] / (df['Next_Open'] + 1e-9)) >= 0.975  
        
        # 3. ì‹œê°€ë³´ë‹¤ ë†’ì€ ì–‘ë´‰ ë§ˆê° (ìœ ì§€)
        solid_close = df['Next_Close'] > df['Next_Open']                     

        # 3ê°œ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±(&)í•´ì•¼ë§Œ 1(ì •ë‹µ), ì•„ë‹ˆë©´ 0(ì˜¤ë‹µ)
        df['Target'] = np.where(hit_target & no_stop_loss & solid_close, 1, 0)
        # ==========================================

        # ë¬´í•œëŒ€ ë° ê²°ì¸¡ì¹˜ ì œê±° (Next_Low, Next_Close í•„ë“œ ì¶”ê°€ í™•ì¸!)
        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['Target', 'Next_Open', 'Next_High', 'Next_Low', 'Next_Close'])
        df = df.dropna()
        all_data.append(df) # (Bull íŒŒì¼ì˜ ê²½ìš° all_processed_data.append(df))
    
    conn.close()
    return pd.concat(all_data, axis=0) if all_data else pd.DataFrame()

# 3. LightGBM ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
def train_hybrid_lgbm():
    target_codes = get_hybrid_top_codes()
    total_df = load_and_preprocess(target_codes)
    
    # ë³€ë™ì„± ë° ì§€í‘œ ê°•ë„ ìœ„ì£¼
    features = ['BB_Pos', 'RSI', 'RSI_Slope', 'Range_Ratio', 'Vol_Momentum', 'Vol_Change', 'ATR', 'BBB', 'BBP']
    
    unique_dates = sorted(total_df['Date'].unique())
    split_date = unique_dates[int(len(unique_dates) * 0.8)]
    
    train_df = total_df[total_df['Date'] < split_date]
    test_df = total_df[total_df['Date'] >= split_date]

    X_train, y_train = train_df[features], train_df['Target']
    X_test, y_test = test_df[features], test_df['Target']

    # --- [ìˆ˜ì •] ë°ì´í„° ë¶„í•  ì´í›„, ëª¨ë¸ ì •ì˜ ë°”ë¡œ ì•ë¶€ë¶„ì— ì¶”ê°€ ---
    
    # 1. í›ˆë ¨ ë°ì´í„°ì˜ ì‹¤ì œ ì •ë‹µ ê°œìˆ˜ í™•ì¸ ë° ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
    neg_count = (y_train == 0).sum()
    pos_count = (y_train == 1).sum()
    
    print(f"\nğŸ“Š [í•™ìŠµ ë°ì´í„° í˜„í™©] ì¼ë°˜(0): {neg_count}ê°œ | ìŠ¤ë‚˜ì´í¼ íƒ€ê²Ÿ(1): {pos_count}ê°œ")
    
    if pos_count == 0:
        print("ğŸš¨ [ë¹„ìƒ] ì •ë‹µ(1) ë°ì´í„°ê°€ 0ê°œì…ë‹ˆë‹¤! ë°ì´í„° ê°€ê³µ í•¨ìˆ˜ì˜ Target ì¡°ê±´ì„ ë‚®ì¶°ì•¼ í•©ë‹ˆë‹¤.")
        dynamic_weight = 1.0
    else:
        # ì˜¤ë‹µì´ ì •ë‹µë³´ë‹¤ ëª‡ ë°° ë§ì€ì§€ ê³„ì‚°í•˜ì—¬ ê·¸ëŒ€ë¡œ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (ì˜ˆ: 99ê°œ/1ê°œ = 99ë°°)
        dynamic_weight = neg_count / pos_count
        print(f"âš–ï¸ [ì²˜ë°©] ì •ë‹µ ì˜ˆì¸¡ì— {dynamic_weight:.1f}ë°°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.\n")

    # 2. LightGBM ëª¨ë¸ ì •ì˜ (ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„° ì¶”ê°€)
    model = LGBMClassifier(
        n_estimators=2000,
        learning_rate=0.005,
        num_leaves=31,
        max_depth=5,
        min_child_samples=20,
        feature_fraction=0.8,
        bagging_fraction=0.8,
        subsample_freq=5,
        lambda_l1=0.1,
        lambda_l2=0.1,
        
        # ğŸš€ í•µì‹¬: ê³„ì‚°ëœ ë™ì  ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ì£¼ì…!
        scale_pos_weight=dynamic_weight, 
        
        random_state=42,
        n_jobs=-1,
        force_col_wise=True,
        importance_type='gain'
    )

    print("[3/5] LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        eval_metric='logloss',
        callbacks=[
            early_stopping(stopping_rounds=100), # 100íšŒ ì„±ëŠ¥ ê°œì„  ì—†ì„ ì‹œ ì¤‘ë‹¨
            log_evaluation(period=100)           # 100íšŒë§ˆë‹¤ ê²°ê³¼ ì¶œë ¥
        ]
    )

    # --- [ìˆ˜ì •] ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€ ë¶€ë¶„ ---
    print("\n[4/5] í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ ê²€ì¦ ì¤‘...")
    
    # 1. ë‹¨ìˆœ 0,1 ì˜ˆì¸¡ì´ ì•„ë‹ˆë¼ 'í™•ë¥ (%)'ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    max_prob = y_pred_proba.max()
    print(f"ğŸ’¡ [AIì˜ ìµœê³  í™•ì‹ ë„] ê°€ì¥ ì •ë‹µì¼ ê²ƒ ê°™ì€ ì¢…ëª©ì˜ í™•ë¥ : {max_prob * 100:.2f}%")
    
    # 2. ìœ ì—°í•œ ì„ê³„ê°’(Threshold) ì ìš©
    threshold = 0.50
    if max_prob < 0.50:
        # AIê°€ 50% ë„˜ê²Œ í™•ì‹ í•˜ëŠ” ê²Œ í•˜ë‚˜ë„ ì—†ë‹¤ë©´, ì„ê³„ê°’ì„ ìµœê³  í™•ì‹ ë„ì˜ 90% ìˆ˜ì¤€ìœ¼ë¡œ ì„ì‹œ í•˜í–¥
        threshold = max_prob * 0.9
        print(f"âš ï¸ 50% ì´ìƒ í™•ì‹ í•˜ëŠ” ì¢…ëª©ì´ ì—†ì–´, ì„ê³„ê°’ì„ {threshold:.3f}ë¡œ ë‚®ì¶°ì„œ ì±„ì í•©ë‹ˆë‹¤.")
        
    y_pred = (y_pred_proba >= threshold).astype(int)
    
    # 3. ê²½ê³  ë©”ì‹œì§€ë¥¼ ë„ëŠ” íŒŒë¼ë¯¸í„°(zero_division=0) ì¶”ê°€
    precision = precision_score(y_test, y_pred, zero_division=0)
    
    print(f"âœ… LightGBM ê²€ì¦ ì •ë°€ë„ (ì„ê³„ê°’ {threshold:.3f} ê¸°ì¤€): {precision:.2%}")

    # ëª¨ë¸ ì €ì¥
    joblib.dump(model, 'hybrid_lgbm_model.pkl')
    joblib.dump(features, 'lgbm_features.pkl')
    print("[5/5] ëª¨ë¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: hybrid_lgbm_model.pkl")

if __name__ == "__main__":
    train_hybrid_lgbm()